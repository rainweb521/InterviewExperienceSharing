

记录下来自己面试的一些问题和经验，期望以后能帮到别人。

[TOC]



# Java篇

## 集合类

### hashmap的数据结构和死锁的生成

HashMap 是我们经常会用到的集合类，JDK 1.7 之前底层使用了数组加链表的组合结构，新添加的元素通过取模的方式，定位 Table 数组位置，然后将元素加入链表头部，这样下次提取时就可以快速被访问到。访问数据时，也是通过取模的方式，定位数组中的位置，然后再遍历链表，依次比较，获取相应的元素。

如果 HasMap 中元素过多时，可能导致某个位置上链表很长。原本 O(1) 查找性能，可能就退化成 O(N),严重降低查找效率。为了避免这种情况，当 HasMap 元素数量满足以下条件时，将会自动扩容,重新分配元素。

```
// size:HashMap 中实际元素数量
//capacity：HashMap 容量，即 Table 数组长度，默认为：16
//loadFactor：负载因子，默认为：0.75
size>=capacity*loadFactor
```

HasMap 将会把容量扩充为原来的两倍，然后将原数组元素迁移至新数组。

 旧数组元素迁移到新数组时，依旧采用『头插入法』，这样将会导致新链表元素的逆序排序。

多线程并发扩容的情况下，链表可能形成死链（环形链表）。一旦有任何查找元素的动作，线程将会陷入死循环,从而引发 CPU 使用率飙升。

***\*1. JDK1.8 改进方案\****

JDK1.8 HashMap 底层结构进行彻底重构，使用数组加链表/红黑树方式这种组合结构。

![image-20200911084956930](assets/image-20200911084956930.png)

新元素依旧通过取模方式获取 Table 数组位置，然后再将元素加入链表尾部。一旦链表元素数量超过 8 之后，自动转为红黑树，进一步提高了查找效率。

由于 JDK1.8 链表采用『尾插入』法，从而避免并发扩容情况下链表形成死链的可能。

### **SynchronizedMap**和**ConcurrentHashMap**

对于并发的情况，我们可以使用 JDK 提供 SynchronizedMap 保证安全。

SynchronizedMap 是一个内部类，只能通过以下方式创建实例。

Map m = Collections.synchronizedMap(**new** HashMap(...));

每个方法内将会使用 synchronized 关键字加锁，从而保证并发安全。

由于多线程共享同一把锁，导致同一时间只允许一个线程读写操作，其他线程必须等待，极大降低的性能。

并且大多数业务场景都是读多写少，多线程读操作本身并不冲突，SynchronizedMap 极大的限制读的性能。

所以多线程并发场景我们很少使用 SynchronizedMap。

**ConcurrentHashMap**

既然多线程共享一把锁，导致性能下降。那么设想一下我们是不是多搞几把锁，分流线程，减少锁冲突，提高并发度。

ConcurrentHashMap 正是使用这种方法，不但保证并发过程数据安全，又保证一定的效率。

**1. JDK1.7**

JDK1.7  ConcurrentHashMap 数据结构如下所示:

![image-20200911085440423](assets/image-20200911085440423.png)

Segament 是一个ConcurrentHashMap内部类，底层结构与 HashMap 一致。另外Segament 继承自 ReentrantLock

当新元素加入 ConcurrentHashMap 时，首先根据 key hash 值找到相应的 Segament。接着直接对 Segament 上锁，若获取成功，后续操作步骤如同 HashMap。

由于锁的存在，Segament 内部操作都是并发安全，同时由于其他 Segament 未被占用，因此可以支持 concurrencyLevel 个线程安全的并发读写。

***\*size 统计问题\****

虽然 ConcurrentHashMap 引入分段锁解决多线程并发的问题，但是同时引入新的复杂度，导致计算 ConcurrentHashMap 元素数量将会变得复杂。

由于 ConcurrentHashMap 元素实际分布在 Segament 中，为了统计实际数量，只能遍历 Segament 数组求和。

为了数据的准确性，这个过程过我们需要锁住所有的 Segament，计算结束之后，再依次解锁。不过这样做，将会导致写操作被阻塞，一定程度降低 ConcurrentHashMap 性能。

所以这里对 ConcurrentHashMap#size 统计方法进行一定的优化。

Segment 每次被修改（写入，删除）,都会对 modCount（更新次数）加 1。只要相邻两次计算获取所有的 Segment modCount 总和一致，则代表两次计算过程并无写入或删除，可以直接返回统计数量。

如果三次计算结果都不一致，那没办法只能对所有 Segment 加锁，重新计算结果。

这里需要注意的是，这里求得 size 数量不能做到 100% 准确。这是因为最后依次对 Segment 解锁后，可能会有其他线程进入写入操作。这样就导致返回时的数量与实际数不一致。

不过这也能被接受，总不能因为为了统计元素停止所有元素的写入操作。

***\*性能问题\****

想象一种极端情况的，所有写入都落在同一个 Segment中，这就导致ConcurrentHashMap 退化成 SynchronizedMap，共同抢一把锁。

***\*2. JDK1.8 改进方案\****

JDK1.8 之后，ConcurrentHashMap 取消了分段锁的设计，进一步减少锁冲突的发生。另外也引入红黑树的结构，进一步提高查找效率。

数据结构如下所示：

![image-20200911085804944](assets/image-20200911085804944.png)

Table 数组的中每一个 Node 我们都可以看做一把锁，这就避免了 Segament 退化问题。

另外一旦 ConcurrentHashMap 扩容， Table 数组元素变多，锁的数量也会变多，并发度也会提高。

总的来说，JDK1.8 使用 CAS 方法加 synchronized 方式，保证并发安全。

ConcurrentHashMap 通过使用分段锁的设计方式，降低锁的粒度，提高并发度。我们可以借鉴这种设计，解决某些热点数据更新问题。

SynchronizedMap 虽然线程安全，但是由于锁粒度太大，导致性能太低，所以也不太适合在多线程使用。

ConcurrentHashMap 由于使用多把锁，充分降低多线程并发竞争的概率，提高了并发度，非常适合在多线程中使用。

### Hashmap为什么这里使用红黑树？而不是其他二叉树呢？



## 多线程

### 为什么要使用线程池

合理的使用线程池，则可以避免把系统搞崩的窘境。总得来说，使用线程池可以带来以下几个好处：

1. 降低资源消耗。通过重复利用已创建的线程，降低线程创建和销毁造成的消耗。
2. 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。
3. 增加线程的可管理型。线程是稀缺资源，使用线程池可以进行统一分配，调优和监控。

